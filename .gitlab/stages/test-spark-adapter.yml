unit-tests-spark-adapter:
  stage: test-spark-adapter
  needs: [build-spark-adapter]
  dependencies:
    - build-spark-adapter
  script:
    - echo "Spark adapter unit tests started"
    - "mvn -pl adapter/spark jacoco:prepare-agent surefire:test jacoco:report"
    - "[ -f adapter/spark/target/jacoco.exec ] && mv -f adapter/spark/target/jacoco.exec adapter/spark/target/jacoco-unit-tests.exec || echo '0' > /dev/null"
  artifacts:
    name: unit-tests-spark-adapter
    expire_in: 1 hour
    when: always
    paths:
      - adapter/spark/reports/jacoco/
      - adapter/spark/target/jacoco-unit-tests.exec

integration-tests-spark-adapter:
  stage: test-spark-adapter
  image: $LINUX_TOOLING_IMAGE
  needs: [build-linux-tooling-image, build-spark-adapter]
  dependencies:
    - build-spark-adapter
  script:
    - echo "Spark adapter integration tests started"
    - "mvn -pl adapter/spark jacoco:prepare-agent-integration failsafe:integration-test failsafe:verify jacoco:report-integration"
    - "[ -f adapter/spark/target/jacoco-it.exec ] && mv -f adapter/spark/target/jacoco-it.exec adapter/spark/target/jacoco-integration-tests.exec || echo '0' > /dev/null"
  artifacts:
    name: integration-tests-spark-adapter
    expire_in: 1 hour
    when: always
    paths:
      - adapter/spark/reports/jacoco/
      - adapter/spark/target/jacoco-integration-tests.exec

mutation-tests-spark-adapter:
  stage: test-spark-adapter
  image: $LINUX_TOOLING_IMAGE
  needs: [build-linux-tooling-image, build-spark-adapter]
  dependencies:
    - build-spark-adapter
  script:
    - echo "Spark adapter mutation tests started"
    - "mvn -pl adapter/spark $PITEST_OPTS pitest:mutationCoverage"
    - "cat adapter/spark/reports/pitest/index.html | awk -F '</?td>' 'FNR == 25 { print $2 }' || echo '0%'"
  coverage: /([0-9]{1,3})%/
  artifacts:
    name: mutation-tests-spark-adapter
    expire_in: 3 hours
    when: always
    paths:
      - adapter/spark/reports/pitest/


line-coverage-spark-adapter:
  stage: test-spark-adapter
  needs: [integration-tests-spark-adapter, unit-tests-spark-adapter, build-spark-adapter]
  dependencies:
    - integration-tests-spark-adapter
    - unit-tests-spark-adapter
    - build-spark-adapter
  script:
    - echo "Started creating Spark adapter line coverage"
    - "rm -rf adapter/spark/reports/jacoco"
    - "mvn -pl adapter/spark jacoco:merge jacoco:report"
    - "cat adapter/spark/reports/jacoco/index.html | grep -Po 'Total.*?([0-9]{1,3})%' || echo '0%'"
  coverage: /([0-9]{1,3})%/
  artifacts:
    name: line-coverage-spark-adapter
    expire_in: 3 hours
    when: always
    paths:
      - adapter/spark/reports/jacoco/
      - adapter/spark/target/jacoco.exec

branch-coverage-spark-adapter:
  stage: test-spark-adapter
  needs: [line-coverage-spark-adapter]
  dependencies:
    - line-coverage-spark-adapter
  script:
    - echo "Started generating Spark adapter branch coverage"
    - "cat adapter/spark/reports/jacoco/index.html | grep -Po '%.*?of.*?([0-9]{1,3})%' || echo '0%'"
  coverage: /([0-9]{1,3})%/


e2e-spark-adapter:
  stage: test-spark-adapter
  image: $SPARK_IMAGE
  needs: [package-spark-adapter-e2e, build-spark-adapter-image]
  dependencies:
    - package-spark-adapter-e2e
    - build-spark-adapter-image
  script:
    - echo "Spark adapter end-to-end run started"
    - echo "This job does not provide coverage metrics, it just verifies the system as a whole functions to some degree"
    - spark-submit --class com.asml.apa.wta.spark.EndToEnd --master local[1] adapter/spark/target/spark-1.0-SNAPSHOT-e2e.jar adapter/spark/src/test/resources/config.json wta-output adapter/spark/src/test/resources/wordcount.txt

e2e-barebones-spark-adapter:
  stage: test-spark-adapter
  image: $SPARK_BAREBONES_IMAGE
  needs: [package-spark-adapter-e2e, build-barebones-spark-adapter-image]
  dependencies:
    - package-spark-adapter-e2e
    - build-barebones-spark-adapter-image
  script:
    - echo "Barebones Spark adapter end-to-end run started"
    - echo "This job does not provide coverage metrics, it just verifies the system as a whole functions in a barebones environment"
    - echo "$SCALA_HOME"
    - echo "$SPARK_HOME"
    - echo "$PATH"
    - spark-submit --class com.asml.apa.wta.spark.EndToEnd --master local[1] adapter/spark/target/spark-1.0-SNAPSHOT-e2e.jar adapter/spark/src/test/resources/config.json wta-output adapter/spark/src/test/resources/wordcount.txt
