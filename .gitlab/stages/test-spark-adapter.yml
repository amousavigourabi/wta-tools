unit-tests-spark-adapter:
  stage: test-spark-adapter
  needs: [build-spark-adapter]
  dependencies:
    - build-spark-adapter
  script:
    - echo "Spark adapter unit tests started"
    - "mvn -pl adapter/spark jacoco:prepare-agent surefire:test jacoco:report"
    - "[ -f adapter/spark/target/jacoco.exec ] && mv -f adapter/spark/target/jacoco.exec adapter/spark/target/jacoco-unit-tests.exec || echo '0' >/dev/null"
  artifacts:
    name: unit-tests-spark-adapter
    expire_in: 20 minutes
    when: always
    paths:
      - adapter/spark/target/jacoco-unit-tests.exec
  cache:
    - key:
        files:
          - pom.xml
          - core/pom.xml
        prefix: test
      paths:
        - .m2/repository

integration-tests-spark-adapter:
  stage: test-spark-adapter
  image: $LINUX_TOOLING_IMAGE
  needs: [build-linux-tooling-image, build-spark-adapter]
  dependencies:
    - build-spark-adapter
  script:
    - echo "Spark adapter integration tests started"
    - "mvn -pl adapter/spark jacoco:prepare-agent-integration failsafe:integration-test failsafe:verify jacoco:report-integration"
    - "[ -f adapter/spark/target/jacoco-it.exec ] && mv -f adapter/spark/target/jacoco-it.exec adapter/spark/target/jacoco-integration-tests.exec || echo '0' >/dev/null"
  artifacts:
    name: integration-tests-spark-adapter
    expire_in: 20 minutes
    when: always
    paths:
      - perf.data
      - adapter/spark/target/jacoco-integration-tests.exec
  cache:
    - key:
        files:
          - pom.xml
          - core/pom.xml
        prefix: test
      paths:
        - .m2/repository

mutation-tests-spark-adapter:
  stage: test-spark-adapter
  image: $LINUX_TOOLING_IMAGE
  needs: [build-linux-tooling-image, build-spark-adapter]
  dependencies:
    - build-spark-adapter
  script:
    - echo "Spark adapter mutation tests started"
    - "mvn -pl adapter/spark $PITEST_OPTS pitest:mutationCoverage"
    - "cat adapter/spark/reports/pitest/index.html | awk -F '</?td>' 'FNR == 25 { print $2 }' || echo '0%'"
  coverage: /([0-9]{1,3})%/
  artifacts:
    name: mutation-tests-spark-adapter
    expire_in: 3 hours
    when: always
    paths:
      - adapter/spark/reports/pitest/
  cache:
    - key:
        files:
          - pom.xml
          - core/pom.xml
        prefix: test
      paths:
        - .m2/repository


line-coverage-spark-adapter:
  stage: test-spark-adapter
  needs: [integration-tests-spark-adapter, unit-tests-spark-adapter, build-spark-adapter]
  dependencies:
    - integration-tests-spark-adapter
    - unit-tests-spark-adapter
  script:
    - echo "Started creating Spark adapter line coverage"
    - "mvn -pl adapter/spark jacoco:merge jacoco:report"
    - "cat adapter/spark/reports/jacoco/index.html | grep -Po 'Total.*?([0-9]{1,3})%' || echo '0%'"
  coverage: /([0-9]{1,3})%/
  artifacts:
    name: line-coverage-spark-adapter
    expire_in: 3 hours
    when: always
    paths:
      - adapter/spark/reports/jacoco/

branch-coverage-spark-adapter:
  stage: test-spark-adapter
  needs: [line-coverage-spark-adapter]
  dependencies:
    - line-coverage-spark-adapter
  script:
    - echo "Started generating Spark adapter branch coverage"
    - "cat adapter/spark/reports/jacoco/index.html | grep -Po '%.*?of.*?([0-9]{1,3})%' || echo '0%'"
  coverage: /([0-9]{1,3})%/


e2e-spark-adapter:
  stage: test-spark-adapter
  image: $SPARK_IMAGE
  needs: [package-spark-adapter-e2e, build-spark-adapter-image]
  dependencies:
    - package-spark-adapter-e2e
  script:
    - echo "Spark adapter end-to-end run started"
    - echo "This job does not provide coverage metrics, it just verifies the system as a whole functions to some degree"
    - spark-submit --class com.asml.apa.wta.spark.EndToEnd --master local[1] adapter/spark/target/spark-1.0-SNAPSHOT-e2e.jar adapter/spark/src/test/resources/config.json wta-output adapter/spark/src/test/resources/wordcount.txt
    - if ! [ -n "$(ls -A wta-output 2>/dev/null)" ] ; then exit 1 ; fi
  artifacts:
    name: e2e-output
    expire_in: 3 hours
    paths:
      - wta-output

e2e-barebones-spark-adapter:
  stage: test-spark-adapter
  image: $SPARK_BAREBONES_IMAGE
  needs: [package-spark-adapter-e2e, build-barebones-spark-adapter-image]
  dependencies:
    - package-spark-adapter-e2e
  script:
    - echo "Barebones Spark adapter end-to-end run started"
    - echo "This job does not provide coverage metrics, it just verifies the system as a whole functions in a barebones environment"
    - spark-submit --class com.asml.apa.wta.spark.EndToEnd --master local[1] adapter/spark/target/spark-1.0-SNAPSHOT-e2e.jar adapter/spark/src/test/resources/config.json wta-output adapter/spark/src/test/resources/wordcount.txt
    - if ! [ -n "$(ls -A wta-output 2>/dev/null)" ] ; then exit 1 ; fi
  artifacts:
    name: barebones-e2e-output
    expire_in: 3 hours
    paths:
      - wta-output
